# 回归模型

预测因变量与自变量之间的关系, 一般要求自变量之间相关程度小.

**可靠性&正确性** 

- 对比图展示拟合效果;

- 拟合优度检验; 

- 参数灵敏性检验(在置信区间内扰动观察对结果影响)
  正常应该不灵敏, 稳定.
  
  

## 线性回归

线性回归区别于线性拟合增加随机误差.

```matlab
b = regress(y,X)
[b,bint] = regress(y,X)
[b,bint,r] = regress(y,X)
[b,bint,r,rint] = regress(y,X)
[b,bint,r,rint,stats] = regress(y,X)
[___] = regress(y,X,alpha)
描述：输入y（因变量，列向量）、X（自变量组成的矩阵，每一列为一个属性）。
b：回归系数，是个向量，X有几列，对应于就有几个回归系数，回归系数顺序与X列顺序对应。
bint：回归系数的区间估计，区间越小精度越高。
r：残差。
rint：置信区间。
stats：用于检验回归模型的统计量。有4个数值：判定（决定）系数r^2，F统计量观测值，检验的p的值，误差方差的估计。
alpha：是显著性水平（缺省时默认0.05）。
其意义和用法如下：r^2的值越接近1，变量的线性相关性越强，说明模型有效；如果满足F，则认为变量与显著地有线性关系。
```

**参数的区间估计**  
对随机变量 $\widehat{\beta}_0 \widehat{\beta}_1$ 的取值进行区间估计，如果区间估计值是一个较短的区间表示模型精度较高。

**相关性检验**

相关系数R的值及F值反映模型是否具有良好线性关系.

回归系数置信区间不包含零点表示模型较好，残差在零点附近也表示模型较好，接着就是利用检验统计量R，F，p　的值判断该模型是否可用。  
（１）相关系数Ｒ的评价：一般地，相关系数绝对值在0.8~1范围内，可判断回归自变量与因变量具有较强的线性相关性。本例Ｒ的绝对值为0.9542，表明线性相关性较强。  
（２）F检验法：当 $F>F_{1-\infty}(m,n-m-1)$ , 即认为因变量与自变量之间显著地有线性相关关系；否则认为因变量 y与自变量X之间线性相关关系不显著。
（３）p值检验：若 $p<\alpha$，则说明因变量与自变量之间显著地有线性相关关系。

以上三种统计推断方法推断的结果是一致的，说明因变量 与自变量之间显著地有线性相关关系，所得线性回归模型可用。

**显著性检验**

所有的假设检验都都需要分析显著性.

P值是用来进行显著性检验的，用来检验变量之间是否有差异以及差异是否显著。

若P值>0.05代表数据之间不存在显著性差异；一般以P ＜ 0.05 为有统计学差异， P＜0.01 为有显著统计学差异，P＜0.001为有极其显著的统计学差异。

**一、相关性和显著性的关系**

**残差分析**

使用求出回归方程计算预测值$\hat y_i$,则残差

$$
e_i=y_i -\hat y_i
$$

观察残差图,对奇异点进行分析.....

可以选择去掉奇异点重新回归.



## 多元回归

最小二乘准则

固定其他初始值, 搜索一个参数找到最优值,..... 

多元非线性->多元线性



****



## 非线性回归

因变量对**回归系数**是非线性的.

**经验公式**

检验: beta作拟合方程, 原始数据和拟合数据在图上对比,展示拟合效果.

非线性回归->(1)换元转化为线性(2)使用非线性回归方法.

回归系数和相应的置信区间

```matlab
nlinfit()
nlparci()
nlintool()
```

非线性回归基于搜索, 需要给定初始值, 决定是否能找到最优解.

### 二次式回归





****

## 逻辑回归 Logistic

计算原理: 使用最大似然估计找到最佳参数



## 逐步回归

处理多个独立变量时, 选出影响显著的自变量建立回归模型.

每次从候选变量中选出一个

```matlab
stepwise(x,y,inmodel,apha)
```

****



## 偏最小二乘回归

变量相关性:

- 最小二乘准则下的**经典多元线性回归分析（MLR）**

- 提取自变量组主成分的**主成分回归分析（PCR)** 

- **偏最小二乘回归方法（PLS）**。

偏最小二乘回归提供一种多对多线性回归建模的方法，特别当两组变量的个数很 多，且都存在多重相关性，而观测数据的数量（样本量）又较少时，用偏最小二乘回归建立的模型具有传统的经典回归分析等方法所没有的优点。 

偏最小二乘回归分析在建模过程中集中了主成分分析，典型相关分析和线性回归分析方法的特点，因此在分析结果中，除了可以提供一个更为合理的回归模型外，还可以同时完成一些类似于主成分分析和典型相关分析的研究内容，提供更丰富、深入的一些信息。



### 优点

与传统多元线性回归模型相比，**偏最小二乘回归**的特点是：  
（1）能够在自变量存在严重多重相关性的条件下进行回归建模；  
（2）允许在样本点个数少于变量个数的条件下进行回归建模；  
（3）偏最小二乘回归在最终模型中将包含原有的所有自变量；  
（4）偏最小二乘回归模型更易于辨识系统信息与噪声（甚至一些非随机性的噪声）；  
（5）在偏最小二乘回归模型中，每一个自变量的回归系数将更容易解释。  
在计算方差和协方差时，求和号前面的系数有两种取法：当样本点集合是随机抽取得到时，应该取1/(n-1)；如果不是随机抽取的，这个系数可取1/n。

### 算法

1. 标准化所有数据

2. 同时在自变量/因变量中提取第一成分 $t_1$ and $u_1$ , 并要求两者相关程度达到最大.

3. 建立因变量$y_1...y_n$与$t_1$的回归.

4. 若达到精度要求则停止,否则继续寻找第二对.

5. 最终提取 r 个自变量成分, 建立$y_1...y_n$ 与 $t_1...t_r$ 的回归方程, 再表示为y与x的方程.
